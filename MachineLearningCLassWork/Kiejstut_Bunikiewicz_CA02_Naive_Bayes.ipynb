{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kiejstut_Bunikiewicz_CA02_Naive_Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdBOz3yFevkW"
      },
      "source": [
        "# Your Name: Kiejstut Bunikiewicz\r\n",
        "\r\n",
        "### Assignment Name: CA02 - Spam eMail Detection using Naive Bayes Classification Algorithm\r\n",
        "\r\n",
        "#### This program is Spam Classifier for eMails that uses the Naive Bayes supervised machine learning algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WikwoOEfBLY"
      },
      "source": [
        "# Program Initialization Section \r\n",
        "\r\n",
        "### Enter Your Import Packages Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc3OddtAes9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b317f450-fd8e-43cf-be10-c3fce12b89d5"
      },
      "source": [
        "# import packages here\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "#Mounting Google Drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6lAwTZofhRf"
      },
      "source": [
        "# Data File Reading Section\r\n",
        "\r\n",
        "Write Code to Read Data Sources Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSUQVdWg_t7"
      },
      "source": [
        "# although they will be used until after the functions are written, we will read the data here\r\n",
        "# make sure to mount your drive first via the pop-out on the left, the third icon will allow you to mount your google drive\r\n",
        "TRAINING_EMAILS = '/content/drive/My Drive/MSBA Colab 2020/ML Algorithms/CA02/Data/train-mails'\r\n",
        "TESTING_EMAILS = '/content/drive/My Drive/MSBA Colab 2020/ML Algorithms/CA02/Data/test-mails'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TskAD4MPn7Q"
      },
      "source": [
        "### Defining the Dict_Maker function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csY2aropF8V"
      },
      "source": [
        "This function builds a Dictionary of most common 3000 words from all the email content. First it adds all words and symbols in the dictionary. Then it removes all non-alpha-numeric characters and any single character alpha-numeric characters. After this is complete it shrinks the Dictionary by keeping only most common 3000 words in the dictionary. It returns the Dictionary.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJDawEtWpCCA"
      },
      "source": [
        "def Dict_Maker(base_dir):\r\n",
        "  complete_words_list = []\r\n",
        "  email_list = [os.path.join(base_dir,file) for file in os.listdir(base_dir)] #creating a list of files from the email folder\r\n",
        "  for email in email_list:\r\n",
        "    with open(email) as e:\r\n",
        "      for sentence in e:\r\n",
        "        word = sentence.split() #splitting the emails into the individual words\r\n",
        "        complete_words_list += word #appending the individual words to the list\r\n",
        "  words_dict = Counter(complete_words_list) #counting the number of words in the list\r\n",
        "  list_to_remove = list(words_dict) #transforming the count back into a list\r\n",
        "\r\n",
        "  for mail in list_to_remove:\r\n",
        "    if mail.isalpha() == False:\r\n",
        "      del words_dict[mail] # this is deleting words that are not alphanumeric characters\r\n",
        "    elif len(mail) == 1:\r\n",
        "      del words_dict[mail] #this line is deleting words 1 letter long, AKA \"stop words\" like \"a\" \r\n",
        "  words_dict = words_dict.most_common(3000) #this is creating a dictionary of the 3000 most common words from the cleaned set of words\r\n",
        "  return words_dict"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64lz7nzgYmnG"
      },
      "source": [
        "### Defining the Mail_Word_Labeller Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDfPnLiApJ7V"
      },
      "source": [
        "This function extracts feature columns and populates their values (Feature Matrix of 3000 comumns and rows equal to the number of email files). The function also analyzes the File Names of each email file and decides if it's a Spame or not based on the naming convention. Based on this the function also creates the Labelled Data Column. This function is used to extract the training dataset as well as the testing dataset and returns the Feature Dataset and the Label column.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdobzoQVpKYN"
      },
      "source": [
        "def Mail_Word_Labeller(emailing_dir):\r\n",
        "  mails = [os.path.join(emailing_dir,filed) for filed in os.listdir(emailing_dir)] #creating a list of files from the folder\r\n",
        "  email_features_matrix = np.zeros((len(mails),3000)) #creating an empty matrix for number of files and 3000 most common words\r\n",
        "  training_labels = np.zeros(len(mails)) #creating an empty set of labels by length of number of files\r\n",
        "  wordcount = 1;\r\n",
        "  emailID = 0;\r\n",
        "  for parcel in mails: #looping through listed files\r\n",
        "    with open(parcel) as post:\r\n",
        "      for ind, line in enumerate(post): #enumerating the file that is being looped through\r\n",
        "        if ind ==2:\r\n",
        "          words = line.split() #splitting the files into individual words\r\n",
        "          for word in words:\r\n",
        "            wordID = 0 #setting a base wordID\r\n",
        "            for ind, d in enumerate(words_dict):\r\n",
        "              if d[0] == word:\r\n",
        "                wordID = ind #these three lines are matching the word that is being looped through with the matching word in the dictionary\r\n",
        "                email_features_matrix[emailID,wordID] = words.count(word) #if there is a match, the number of occurrences is counted\r\n",
        "      training_labels[emailID] = 0; #this is setting a base emailID, assuming the email is not spam\r\n",
        "      filepathTokens = parcel.split('/')\r\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\r\n",
        "      if lastToken.startswith(\"spmsg\"):\r\n",
        "        training_labels[emailID] = 1; #the email id is reassigned if the end of the file name indicates the training data is a spam file\r\n",
        "        wordcount = wordcount + 1 # if the file is spam, the wordcount variable is changed, indicating an occurence of the word in a spam file\r\n",
        "      emailID = emailID + 1 #this file is creating a new emailID for the next email\r\n",
        "  return email_features_matrix, training_labels\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbIK5Uy4QaDx"
      },
      "source": [
        "## Running the Naive Bayes, Sanity Check, and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfnVtA_ppWOb"
      },
      "source": [
        "The section is the main Program that calls the above two functions and gets executed first. First it \"trains\" the model using model.fit function and Training Dataset. After that it scores the Test Data set by running the Trained Model with the Test Data set. At the end it prints the model performance in terms of accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4QsoYvdpWnQ",
        "outputId": "a044669c-8f40-478c-ea31-1cb3f3a6b465"
      },
      "source": [
        "# Finding Popular Words\r\n",
        "words_dict = Dict_Maker(TRAINING_EMAILS) #creating a base dictionary of most common words using the training set\r\n",
        "\r\n",
        "# Extracting the Counts and ID from the Test and Training Sets\r\n",
        "print (\"Reading and Processing emails from train-mails and test-mails folders\")\r\n",
        "email_features_matrix, training_labels = Mail_Word_Labeller(TRAINING_EMAILS) #this extracts ID (the emailid# and the wordID #), whether email is spam, and whether the popular words are within the training set\r\n",
        "testing_features_matrix, test_labels = Mail_Word_Labeller(TESTING_EMAILS) #same, but for test set \r\n",
        "\r\n",
        "#Gauss Naive Bayes Model\r\n",
        "model = GaussianNB()  #we are using a model that assumes the words are normally distributed and independent of each other\r\n",
        "\r\n",
        "print (\"Training Model using Gaussian Naive Bayes algorithm .....\")\r\n",
        "model.fit(email_features_matrix, training_labels) #fitting the model using the training set. this is creating a set of probability of a specific word occurring in spam vs. nonspam emails\r\n",
        "\r\n",
        "#Checking features\r\n",
        "print(\"Test of Whether Number of Occurrences are Being Recorded...\")\r\n",
        "print(list(email_features_matrix)[1]) #function is successfully counting the number of occurrences of the popular words in each email\r\n",
        "print(\"Testing if Nonspam/Spam Distinciton is Being Made...\")\r\n",
        "print(list(training_labels)[0:10]) #function is outputting indications of whether the word is spam(1) or not(0)\r\n",
        "\r\n",
        "#Sanity Check to See if Data was correctly transferred from the files\r\n",
        "# we should have an equal number of spam and nonspam data in the training data, adding up to 702\r\n",
        "print(\"Sanity Check by counting number of files\")\r\n",
        "print(\"Number of Nonspam in Training...\")\r\n",
        "print(list(training_labels).count(0))\r\n",
        "print(\"Number of Spam in Training...\")\r\n",
        "print(list(training_labels).count(1)) #351 emails in each category, this matches our expectations\r\n",
        "\r\n",
        "print (\"Training completed\")\r\n",
        "print (\"Testing trained model to predict Test eMail labels...\")\r\n",
        "predicted_labels = model.predict(testing_features_matrix) #predicting the spam v. nonspam with the test set\r\n",
        "print(list(predicted_labels)[0:5]) #as seen from the list, the numbers are designating 0 for nonspam and 1 for spam\r\n",
        "\r\n",
        "#count of predicted nonspam and spam vs. real count\r\n",
        "print('Predicted Number of Nonspam in Test Data:')\r\n",
        "print(list(predicted_labels).count(0)) #137 nonspam predicted\r\n",
        "print('Predicted Number of Spam in Test Data:') \r\n",
        "print(list(predicted_labels).count(1)) #123 spam predicted\r\n",
        "print('Actual Number of Nonspam in Test Data:')\r\n",
        "print(list(test_labels).count(0)) #130 nonspam actual\r\n",
        "print('Actual Number of Spam in Test Data:') \r\n",
        "print(list(test_labels).count(1)) #130 spam actual\r\n",
        "\r\n",
        "# a small number of spam emails get through, but it does not look like there are any false positives\r\n",
        "#This is because the number of spam is lower than expected. However, there could be both types of errors.\r\n",
        "\r\n",
        "print (\"Completed classification of the Test eMail Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\r\n",
        "print (accuracy_score(test_labels, predicted_labels)) #comparing the correct answers (supervised learing) with the model's predictions(TRAINING_EMAILS)\r\n",
        "# It looks like 96.5% is a good accuracy rate. I think the number of emails falsely described as spam would increase if we set the default to assume\r\n",
        "# that the emails were spam."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading and Processing emails from train-mails and test-mails folders\n",
            "Training Model using Gaussian Naive Bayes algorithm .....\n",
            "Test of Whether Number of Occurrences are Being Recorded...\n",
            "[3. 2. 3. ... 0. 0. 0.]\n",
            "Testing if Nonspam/Spam Distinciton is Being Made...\n",
            "[1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
            "Sanity Check by counting number of files\n",
            "Number of Nonspam in Training...\n",
            "351\n",
            "Number of Spam in Training...\n",
            "351\n",
            "Training completed\n",
            "Testing trained model to predict Test eMail labels...\n",
            "[1.0, 1.0, 0.0, 0.0, 0.0]\n",
            "Predicted Number of Nonspam in Test Data:\n",
            "137\n",
            "Predicted Number of Spam in Test Data:\n",
            "123\n",
            "Actual Number of Nonspam in Test Data:\n",
            "130\n",
            "Actual Number of Spam in Test Data:\n",
            "130\n",
            "Completed classification of the Test eMail Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}